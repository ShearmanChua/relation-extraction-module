{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/shearman/Desktop/work/NER-module/venv/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\"\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\"\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: setuptools in /home/shearman/Desktop/work/NER-module/venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch) (44.0.0)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: wheel, nvidia-cublas-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 wheel-0.38.4\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shearman/Desktop/work/NER-module/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongformerForMaskedLM, LongformerModel, LongformerTokenizer, LongformerConfig, AdamW, get_linear_schedule_with_warmup\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = LongformerConfig.from_pretrained(\n",
    "            'allenai/longformer-base-4096')\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained(\n",
    "    'allenai/longformer-base-4096')\n",
    "\n",
    "longformer = LongformerModel.from_pretrained(\n",
    "    'allenai/longformer-base-4096', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"what da heck is wrong with the guy named Shearman Chua Wei Jie? How's the food ShearmanChua?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'Ġda',\n",
       " 'Ġheck',\n",
       " 'Ġis',\n",
       " 'Ġwrong',\n",
       " 'Ġwith',\n",
       " 'Ġthe',\n",
       " 'Ġguy',\n",
       " 'Ġnamed',\n",
       " 'ĠShe',\n",
       " 'ar',\n",
       " 'man',\n",
       " 'ĠCh',\n",
       " 'ua',\n",
       " 'ĠWei',\n",
       " 'ĠJ',\n",
       " 'ie',\n",
       " '?',\n",
       " 'ĠHow',\n",
       " \"'s\",\n",
       " 'Ġthe',\n",
       " 'Ġfood',\n",
       " 'ĠShe',\n",
       " 'ar',\n",
       " 'man',\n",
       " 'Ch',\n",
       " 'ua',\n",
       " '?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 12196, 2955, 17835, 16, 1593, 19, 5, 2173, 1440, 264, 271, 397, 732, 4324, 27080, 344, 324, 116, 1336, 18, 5, 689, 264, 271, 397, 4771, 4324, 116, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.stack([torch.tensor(t[\"input_ids\"])]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 12196,  2955, 17835,    16,  1593,    19,     5,  2173,  1440,\n",
       "           264,   271,   397,   732,  4324, 27080,   344,   324,   116,  1336,\n",
       "            18,     5,   689,   264,   271,   397,  4771,  4324,   116,     2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'Ġda',\n",
       " 'Ġheck',\n",
       " 'Ġis',\n",
       " 'Ġwrong',\n",
       " 'Ġwith',\n",
       " 'Ġthe',\n",
       " 'Ġguy',\n",
       " 'Ġnamed',\n",
       " 'ĠShe',\n",
       " 'ar',\n",
       " 'man',\n",
       " 'ĠCh',\n",
       " 'ua',\n",
       " 'ĠWei',\n",
       " 'ĠJ',\n",
       " 'ie',\n",
       " '?',\n",
       " 'ĠHow',\n",
       " \"'s\",\n",
       " 'Ġthe',\n",
       " 'Ġfood',\n",
       " 'ĠShe',\n",
       " 'ar',\n",
       " 'man',\n",
       " 'Ch',\n",
       " 'ua',\n",
       " '?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what da heck is wrong with the guy named Shearman Chua Wei Jie? How's the food ShearmanChua?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = tokenizer.convert_tokens_to_string(['ĠShe','ar','man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(40, 49), (78, 87)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Find all indices of 'the'\n",
    "indices_object = re.finditer(pattern=span, string=string)\n",
    "indices = [index.span() for index in indices_object]\n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Shearman'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[40:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "longformer.save_pretrained(\"./longformer/model/\")\n",
    "tokenizer.save_pretrained(\"./longformer/tokenizer/\")\n",
    "config.save_pretrained(\"./longformer/config/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'allenai/longformer-base-4096')\n",
    "# config = AutoConfig.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./longformer/tokenizer/tokenizer_config.json',\n",
       " './longformer/tokenizer/special_tokens_map.json',\n",
       " './longformer/tokenizer/vocab.json',\n",
       " './longformer/tokenizer/merges.txt',\n",
       " './longformer/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./longformer/tokenizer/\")\n",
    "# config.save_pretrained(\"./longformer/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    './longformer/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
